# -*- coding: utf-8 -*-
"""
Created on Tue Aug 23 16:06:00 2022

@author: nurekeye

Fitting XAS Kinetics data from SACLA
csv files are generated by sorting code
lmfit package is used
"""

#import libraries
import time
start_time = time.time()

import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
from collections import defaultdict
import numpy as np
import pandas as pd
import lmfit as lf
from scipy import special
from scipy import signal

#define functions for fitting
def custom_errfunc(x,x0,y0,a,g):
    return y0 + a*(1+ special.erf((x-x0) / (g/np.sqrt(2)) ) )

#exponent multiplied by Heviside function. While x0 in the exponent is unnecessary,
#it is easier to interpret fit results when it's there
def custom_exp_hevi(x,amp_exp,tau,x0):
    return amp_exp*np.exp(-(x-x0)/tau)*np.heaviside(x-x0,0.5)

#Sum of two exponents multiplied by Heviside function.
def custom_double_exp_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0):
    return ( (amp_exp1*np.exp(-(x-x0)/tau1)) + (amp_exp2*np.exp(-(x-x0)/tau2)) ) * np.heaviside(x-x0,1)

#Sum of a positive exponent and a negative exponent multiplied by Heviside function.
def custom_exp_negative_hevi(x,amp_exp1,tau1,amp_exp2,tau2,x0):
    return ( (amp_exp1*np.exp(-(x-x0)/tau1)) + (amp_exp2 - amp_exp2*np.exp(-(x-x0)/tau2)) ) * np.heaviside(x-x0,1)

#Sum of two positive exponents and a negative exponent multiplied by Heviside function.
def custom_double_exp_negative_hevi(x,amp_exp1,tau1,amp_exp2,tau2,amp_exp3,tau3,x0):
    return ( (amp_exp1*np.exp(-(x-x0)/tau1)) + (amp_exp2*np.exp(-(x-x0)/tau2)) + (amp_exp3 - amp_exp3*np.exp(-(x-x0)/tau3)) ) * np.heaviside(x-x0,1)

# plt.plot(Delays_on, custom_exp_negative_hevi(Delays_on,1,20,0.5,1,0))

#Gaussian. Coefficient 2.3548200450309493 makues sure that width is equal to FWHM of a Gaussian,
#hence, to an FWHM of a derivative of a rise-time of a fitted function custom_conv()
def custom_gauss(x,amp_gauss,width):
    return amp_gauss * ( 1/( (width/2.3548200450309493)*np.sqrt(2*np.pi)) ) * np.exp( -((x)**2) / (2*((width/2.3548200450309493)**2) ) )

#Convolution of functions custom_exp_hevi() and custom_gauss(). Convolution is not evaluated over the whole time range.
#Expected rise time is about 300 fs, 
#so a Gaussian of such a width is almost fully defind within 10*width, i.e. within 3000 fs 
#(that's what k-1500,k+1500 refers to, k is the center of a Gaussion).
#Evaluating the convolution over the whole time range doesn't improve the result.
#Also,since bin size in data is 25 fs, the grid is 5 fs, that's where 601 comes from.
def custom_conv(x,x0,y0,amp_gauss,width,amp_exp,tau):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1.5, xk+1.5, 601) #set the grid over which to integrate
        f1 = custom_exp_hevi(grid_x,amp_exp,tau,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Convolution of functions custom_double_exp_hevi() and custom_gauss()
def custom_conv2(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1.5, xk+1.5, 601) #set the grid over which to integrate
        f1 = custom_double_exp_hevi(grid_x,amp_exp1,tau1,amp_exp2,tau2,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Convolution of functions custom_custom_exp_negative_hevi() and custom_gauss()
def custom_conv3(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1.5, xk+1.5, 601) #set the grid over which to integrate
        f1 = custom_exp_negative_hevi(grid_x,amp_exp1,tau1,amp_exp2,tau2,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Convolution of functions custom_double_exp_negative_hevi() and custom_gauss()
def custom_conv4(x,x0,y0,amp_gauss,width,amp_exp1,tau1,amp_exp2,tau2,amp_exp3,tau3):
    res_f = [] #final convoluted function
    for xk in x: #
        res_t = [] #overlap between 2 functions at a single time-shift between them
        grid_x = np.linspace(xk-1.5, xk+1.5, 601) #set the grid over which to integrate
        f1 = custom_double_exp_negative_hevi(grid_x,amp_exp1,tau1,amp_exp2,tau2,amp_exp3,tau3,x0)
        f2 = custom_gauss(xk-grid_x,amp_gauss,width)
        res_t=f1*f2 #mulitplication of 2 functions
        # integral = sum(res_t)
        integral = np.trapz( y=list(res_t), x=list(grid_x) ) #evaluating the integral
        res_f.extend([integral]) 
    return ( y0 + np.array(res_f) )

#Data directory and directory where to save the results
# Directory ='C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Data/20221027/'
# Filename = 'Iodide_EX200_70uW_100mM_night' 

Directory ='C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Data/20221028/'
Filename = 'Bromide_EX200_65uW_100mM_night'

# Directory ='C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Data/20221029/'
# Filename = 'Chloride_EX200_70uW_1000mM_night'

# Directory = 'C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Data/20221102/'
# Filename = 'Iodide_EX240_0.99mW_100mM'

# Directory = 'C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Data/20221030/'
# Filename = 'Iodide_EX400_14.00mW_100mM'

Save_Directory = 'C:/Users/nurekeye/Desktop/Projects/CNM_10-2022/Analysis/2023_07_07/'


# Create empty dictionaries to fill them with Pandas DataFrames, each key corresponds to a run
data = {} #timing tool corrected
datau = {} #uncorrected

#load the data. 

data = pd.read_csv(Directory+Filename+'.ufs.csv', delimiter=',', index_col=0, header=None).astype(float).transpose()
# plt.plot(data[0], data[780.3])

Runs = [574.9,780.3]

#Set the model with lmfit
#Create empty dictionaries to fill with fit results
fit_res = {}
fit_report = {}
fit_range_u=10000 #Upper limit of fitting range in fs, lower limit hasn't been used so far

#Fitting itself. Standard deviation is used as weights.
#Common Levenbergâ€“Marquardt algorithm didn't work well, and among 20 different algorithms
#"differential evolution" method was the one with the best results, also it didn't take forever
for k in Runs:
    Delays_on = np.array( data[0][~np.isnan(data[k])] ) 
    TFY_on = np.array( data[k][~np.isnan(data[k])] )
    
    baseline = np.nanmean( TFY_on[Delays_on<0.0] )
    y_axis = TFY_on[Delays_on<fit_range_u] - baseline
    x_axis = Delays_on[Delays_on<fit_range_u]
    # stddev = np.array(data[str(k)].TFY_on_std[(data[str(k)].Delays_on<fit_range_u)])
    
    mid_value =max(TFY_on-baseline)/2
    list_a = y_axis[x_axis<3]
    mid_value_real = list_a[min(range(len(list_a)), key=lambda i: abs(list_a[i]-mid_value))]
    t0 = x_axis[y_axis == mid_value_real]
    t0 = float(t0)
    amp_exp0 = float(abs(mid_value*2))
    
# =============================================================================
#     gmodel = lf.Model(custom_conv)
#     params = lf.create_params( x0=dict(value=t0, vary=True, min=0.5, max=2), #Time zero in ps
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=0.3, vary=True, min=0.1, max=0.5), #Gaussian width
#                           amp_exp=dict(value=amp_exp0, vary=True, min=0.0001, max=0.002), #Exponent amplitude in a.u.
#                           tau=dict(value=20, vary=True, min=10, max=50) ) #Exponent lifetime in ps
# =============================================================================
    
# =============================================================================
#     gmodel = lf.Model(custom_conv2)
#     params = lf.create_params( x0=dict(value=t0, vary=True, min=0.5, max=2), #Time zero in ps
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=0.3, vary=True, min=0.1, max=0.5), #Gaussian width
#                           amp_exp1=dict(value=amp_exp0/2, vary=True, min=0.0001, max=0.002), #Exponent amplitude in a.u.
#                           tau1=dict(value=20, vary=True, min=10, max=50), #Exponent lifetime in ps
#                           amp_exp2=dict(value=amp_exp0/2, vary=True, min=0.0001, max=0.002), #Exponent amplitude in a.u.
#                           tau2=dict(value=200, vary=True, min=150) ) #Exponent lifetime in ps
# =============================================================================
    
# =============================================================================
#     gmodel = lf.Model(custom_conv3)
#     params = lf.create_params( x0=dict(value=t0, vary=True, min=0.5, max=2), #Time zero in ps
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                           width=dict(value=0.3, vary=True, min=0.1, max=0.5), #Gaussian width
#                           amp_exp1=dict(value=amp_exp0/2, vary=True, min=0.0001, max=0.002), #Exponent amplitude in a.u.
#                           tau1=dict(value=20, vary=True, min=10, max=50), #Exponent lifetime in ps
#                           amp_exp2=dict(value=amp_exp0/2, vary=True, min=0.0001, max=0.002), #Exponent amplitude in a.u.
#                           tau2=dict(value=0.5, vary=True, min=0.1, max=3) ) #Negative Exponent lifetime in ps
# =============================================================================

    gmodel = lf.Model(custom_conv4)
    params = lf.create_params( x0=dict(value=t0, vary=True, min=0.5, max=2), #Time zero in ps
                          y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
                          amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
                          width=dict(value=0.3, vary=True, min=0.1, max=0.5), #Gaussian width
                          amp_exp1=dict(value=amp_exp0/3, vary=True, min=0.0001, max=0.3), #Exponent amplitude in a.u.
                          tau1=dict(value=20, vary=True, min=10, max=50), #Exponent lifetime in ps
                          amp_exp2=dict(value=amp_exp0/3, vary=True, min=0.0001, max=0.3), #Exponent amplitude in a.u.
                          tau2=dict(value=1, vary=True, min=0.3, max=1000), #Exponent lifetime in ps
                          amp_exp3=dict(value=amp_exp0/3, vary=True, min=0.0001, max=0.3), #Exponent amplitude in a.u.
                          tau3=dict(value=0.3, vary=True, min=0.1, max=0.5) ) #Negative Exponent lifetime in ps
# =============================================================================
#     gmodel = lf.Model(custom_errfunc)
#     params = lf.create_params( x0=dict(value=0.1, vary=True, min=0.5, max=2), #Time zero in ps
#                           y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                           a=dict(value=0.0006, vary=True, min=0.0001, max=0.002), #Error function amplitude in a.u.
#                           g=dict(value=0.237, vary=True, min=0.1, max=0.5)) #Error function width in ps
# =============================================================================
    
    result = gmodel.fit(y_axis, params=params, x=x_axis, 
                        # weights = 1/stddev,
                        method = 'nelder')
    fit_res[str(k)] = result #save fit results in internal lmfit format
    fit_report[str(k)] = result.fit_report() #save fit report
    # lf.model.save_modelresult(fit_res[str(k)], Save_Directory + Filename + '.sav') #saving fit results in internal lmfit format in .sav file for 2.9 uJ

    #Plotting the fit results.    
# =============================================================================
#     plt.figure(str(k),figsize=[16,8], dpi=200)
#     # plt.subplot(2,1,1)
#     plt.plot(x_axis, y_axis, '.', label='data')
#     # plt.plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
#     plt.plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
#     plt.legend(loc='lower right')
#     plt.xlim([min(x_axis)-max(x_axis), max(x_axis)])
#     plt.ylabel('Intensity (a.u.)')
#     plt.xlabel('Delay (ps)')
#     plt.title('Iodide, 100 mM, 400 nm Pump, 780 nm Probe')
#     plt.text(min(x_axis)-max(x_axis), min(y_axis), s=result.fit_report(), fontsize=6)
#     # plt.subplot(2,1,2)
#     # plt.plot(x_axis, fit_res[str(k)].residual)
# =============================================================================
    
    figs, axes = plt.subplots(2,1, sharex=True, height_ratios=[5,1], num=int(k)*2, figsize=[16,8], dpi=200)
    figs.subplots_adjust(hspace=0)
    axes[0].plot(x_axis, y_axis, '.', label='data')
    axes[0].plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
    axes[0].plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
    axes[0].legend(loc='upper right')
    axes[0].set_ylabel('Intensity (a.u.)')
    axes[0].text(min(x_axis)-max(x_axis), min(y_axis), s=result.fit_report(), fontsize=7)
    axes[0].set_title('Iodide, 100 mM, 400 nm Pump, 780 nm Probe')
    axes[1].plot(x_axis, fit_res[str(k)].residual)
    # axes[1].set_ylabel('Resid')
    axes[1].set_xlim([min(x_axis)-max(x_axis), max(x_axis)])
    axes[1].set_xlabel('Delay (fs)')
    
    mng = plt.get_current_fig_manager()
    mng.window.showMaximized()
    
    # plt.savefig(Save_Directory + Filename + '.png',dpi=300) #saving figures in .png file for 2.9 uJ
    print(fit_res[str(k)].values)

# figs, axes = plt.subplots(2,1,sharex=True)
# figs.subplots_adjust(hspace=0)
# axes[0].plot(x_axis, y_axis, '.', label='data')
# axes[0].plot(x_axis, fit_res[str(k)].init_fit, '--', label='initial fit')
# axes[0].plot(x_axis, fit_res[str(k)].best_fit, '-', label='best fit')
# axes[0].legend(loc='upper right')
# axes[0].set_xlim([min(x_axis)-max(x_axis), max(x_axis)])
# axes[0].set_ylabel('Intensity (a.u.)')
# axes[0].set_xlabel('Delay (fs)')
# axes[0].text(min(x_axis)-max(x_axis), min(y_axis), s=result.fit_report(), fontsize=7)


# divider = make_axes_locatable(axes[1])
# axes[1] = divider.append_axes("bottom", size='10%')
# axes[1].plot(x_axis, fit_res[str(k)].residual)

#%% Now attempting to normalized the data by correcting for the amplitude of the exponent and time-zero     
'''
New_Delays = {}
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # amplitude = fit_res[str(k)].values['amp_exp']
    amplitude = fit_res[str(k)].values['amp_exp1'] + fit_res[str(k)].values['amp_exp2']

    plt.figure(10) #plot the data corrected for exponent amplitude only
    plt.plot( data[str(k)].Delays_on, (data[str(k)].TFY_on - baseline) / amplitude)
    plt.xlim([-600,5000])
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (ps)')
    
    plt.figure(11) #plot the fitted functions, uncorrected
    plt.plot(data[str(k)].Delays_on[(data[str(k)].Delays_on<fit_range_u)], fit_res[str(k)].best_fit, '-', label='best fit')
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (ps)')
    
    #Shift the time-zeros for the data so that x0 = 0.
    #Since binning is 25 fs, the shifts are made to be the integers of 25 fs,
    #Of course, the remainders are taken into account as well.
    #As an example, assume that shift is 160 fs. Remainder in this case is 10 fs, so the data is shifed by -150 fs.
    #Now assume the shift is 170 fs. Remainder is 20 fs, but shifting by -150 fs is worse than shifting by -175 fs.
    #To account for that, the threshold for such decisions is 12.5 fs
    if fit_res[str(k)].values['x0'] < 0: #this is to take into account the sign of time-zero according to fit
        sign = -1 #if sign is negative
    else:
        sign = 1 #if sign is positive
    if abs(fit_res[str(k)].values['x0']%25) < 12.5: #checking if the remainder is more or less than 12.5 fs and shifting accoringly
        New_Delays[str(k)] = data[str(k)].Delays_on - ( fit_res[str(k)].values['x0'] - (sign*(abs(fit_res[str(k)].values['x0'])%25)) )
    else:
        New_Delays[str(k)] = data[str(k)].Delays_on - ( fit_res[str(k)].values['x0'] - (sign*(abs(fit_res[str(k)].values['x0'])%25)) + 25 ) #note extra +25 fs
    
    plt.figure(12) #plot the data corrected for exponent amplitude and time-zero
    plt.plot(New_Delays[str(k)], (data[str(k)].TFY_on - baseline) / amplitude )
    plt.xlim([-600,5000])
    plt.legend(data, loc='lower right')
    plt.ylabel('Intensity (a.u.)')
    plt.xlabel('Delay (ps)')
    
# plt.figure(10,figsize=[16,8], dpi=200)
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()    
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_amplitude-corrected-only.png',dpi=300) #saving figures in .png file
# plt.figure(11,figsize=[16,8], dpi=200)  
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()  
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_fitted-curves.png',dpi=300) #saving figures in .png file
# plt.figure(12,figsize=[16,8], dpi=200)
# mng = plt.get_current_fig_manager()
# mng.window.showMaximized()    
# plt.savefig(Save_Directory+EnergyXray+EnergyLaser+PolarisationLaser+'/' + EnergyXray + EnergyLaser + PolarisationLaser + '_amplitude-and-time-zero-corrected.png',dpi=300) #saving figures in .png file

Delays_temp = []
TFY_temp = []
TFY_std_temp = []
for k in Runs:
    baseline = np.nanmean( data[str(k)].TFY_off )
    # amplitude = fit_res[str(k)].values['amp_exp']
    amplitude = fit_res[str(k)].values['amp_exp1'] + fit_res[str(k)].values['amp_exp2']
    
    Delays_temp.extend( list(New_Delays[str(k)]) )
    TFY_temp.extend( list((data[str(k)].TFY_on - baseline) / amplitude) )
    TFY_std_temp.extend( (data[str(k)].TFY_on_std / amplitude) )
    
TFY_sorted_by_Delay = defaultdict(list)
for key,value in zip(Delays_temp,TFY_temp):
    try:
        TFY_sorted_by_Delay[key].append(value)
    except KeyError:    
        print('ERRRRRORRRRR')
        
TFY_std_sorted_by_Delay = defaultdict(list)
for key,value in zip(Delays_temp,TFY_std_temp):
    try:
        TFY_std_sorted_by_Delay[key].append(value)
    except KeyError:    
        print('ERRRRRORRRRR')

Delays_fin = []
TFY_fin = []
TFY_std_fin = []
for key in TFY_sorted_by_Delay:
    if np.isnan(key)==False:
        Delays_fin.append(key)        
        TFY_fin.append(np.nanmean(TFY_sorted_by_Delay[key]))
for key in TFY_std_sorted_by_Delay:
    if np.isnan(key)==False:
        TFY_std_fin.append(np.sqrt( sum(np.array(TFY_std_sorted_by_Delay[key])**2) / len(np.array(TFY_std_sorted_by_Delay[key])) ))

TFY_fin = [x for _, x in sorted(zip(Delays_fin, TFY_fin))]
TFY_std_fin = [x for _, x in sorted(zip(Delays_fin, TFY_std_fin))]
Delays_fin = [x for _, x in sorted(zip(Delays_fin, Delays_fin))]

# plt.figure(13)
# plt.errorbar(Delays_fin,TFY_fin,yerr=TFY_std_fin)

Delays_fin = np.array(Delays_fin)
TFY_fin = np.array(TFY_fin)
TFY_std_fin = np.array(TFY_std_fin)

# =============================================================================
# params_fin = lf.create_params( x0=dict(value=20, vary=True, min=-100, max=100), #Time zero in fs
#                       y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
#                       amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
#                       width=dict(value=270, vary=True, min=100, max=500), #Gaussian width
#                       amp_exp=dict(value=1, vary=True, min=0.8, max=1.2), #Exponent amplitude in a.u.
#                       tau=dict(value=13583, vary=True, min=10000, max=50000) ) #Exponent lifetime in fs
# =============================================================================

params_fin = lf.create_params( x0=dict(value=0, vary=True, min=-100, max=100), #Time zero in fs
                      y0=dict(value=0, vary=False, min=-0.1, max=0.1), #Background level in a.u., should be zero since LaserOFF is subtracted, hence, vary=False
                      amp_gauss=dict(value=1, vary=False, min=0.1, max=2), #Gaussian amplitude. Keep at 1 and vary=False, it means that amplitude of the fitted function is almost equal to the amplitude of the exponent
                      width=dict(value=300, vary=False, min=100, max=500), #Gaussian width
                      amp_exp1=dict(value=0.5, vary=True, min=0.1, max=1), #Exponent amplitude in a.u.
                      tau1=dict(value=19486, vary=True, min=10000, max=50000), #Exponent lifetime in fs
                      amp_exp2=dict(value=0.5, vary=True, min=0.1, max=1), #Exponent amplitude in a.u.
                      tau2=dict(value=200000, vary=True, min=10000) ) #Exponent lifetime in fs
   
y_axis = np.array(TFY_fin[(Delays_fin<fit_range_u)])
x_axis = np.array(Delays_fin[(Delays_fin<fit_range_u)])
stddev = np.array(TFY_std_fin[(Delays_fin<fit_range_u)])

result_fin = gmodel.fit(y_axis, params_fin, x=x_axis,
                    weights = 1/stddev,
                    method = 'nelder')
fit_res_fin = result_fin
fit_report_fin = result_fin.fit_report()
# lf.model.save_modelresult(fit_res_fin, Save_Directory + EnergyXray + EnergyLaser + PolarisationLaser +'_averaged_fitted.sav')

plt.figure(14,figsize=[16,8], dpi=200)
plt.plot(x_axis, y_axis, '.', label='data')
plt.plot(x_axis, fit_res_fin.init_fit, '--', label='initial fit')
plt.plot(x_axis, fit_res_fin.best_fit, '-', label='best fit')
plt.legend(loc='lower right')
plt.xlim([min(x_axis)-max(x_axis), max(x_axis)])
plt.ylabel('Intensity (a.u.)')
plt.xlabel('Delay (ps)')
plt.text(min(x_axis)-max(x_axis), min(y_axis), s=result_fin.fit_report(), fontsize=7)
mng = plt.get_current_fig_manager()
mng.window.showMaximized()
# plt.savefig(Save_Directory + EnergyXray + EnergyLaser + PolarisationLaser +'_averaged_fitted.png',dpi=300)
print(fit_res_fin.values)
# '''

print("--- %s seconds ---" % (time.time() - start_time))
   
#%% testing Heviside function
'''
def custom_hevi(x,x0,b):
    return b*np.heaviside(x-x0,1)

x = np.linspace(-15, 15, 1000)
data = custom_hevi(x,1,3) + np.random.normal(0, 0.1, x.size)

popt, pcov = curve_fit(custom_hevi, x, data, p0=[5, 5])
plt.figure(1)
plt.plot(x, custom_hevi(x, *popt))
plt.plot(x,data)
par = np.sqrt(np.diag(pcov))
residual = custom_hevi(x, *popt) - data

gmodel = lf.Model(custom_hevi)
params = lf.create_params( x0=dict(value=5, vary=True, min=-1, max=5, brute_step=0.2), 
                      b=dict(value=5, vary=True, min=-1, max=5, brute_step=0.2) )
result = gmodel.fit(data, params, x=x, method='brute')

print(result.fit_report())
plt.figure(2)
plt.plot(x, data, 'o')
plt.plot(x, result.init_fit, '--', label='initial fit')
plt.plot(x, result.best_fit, '-', label='best fit')
plt.legend()
'''

#%% Fitting boundaries
'''
x0l = -200; x0u = 500 #Time zero, set as a shift of a Heaviside function
y0l= 0; y0u = 0.055 #Background level
al = 0.2; au = 1.2 #Amplitude of a Gaussian
gl = 250; gu = 350 #FWHM of a Gaussian, should be same as rise time
bl = 0.03; bu = 0.2 #Amplitude of an exponent
taul = 20000; tauu = 35000 #Lifetime of an exponent
fit_range_u = 5000

fit_param = {}
fit_param2 = {}
fit_param3 = {}
chisq = {}
for k in Runs:
    # popt, pcov = curve_fit(custom_conv, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
    #                         p0=[100, 0.05, 0.9, 300, 0.136, 33000],
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]),
    #                         absolute_sigma=True,
    #                         sigma=data[str(k)].TFY_on_std[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]/np.sqrt(data[str(k)].N_values_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]) )
    popt, pcov, ac,acd,acdc = curve_fit(custom_conv, 
                            data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
                            data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] - data[str(k)].TFY_off[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)] , 
                            p0=[0.1, 20, 300, 20000],
                            bounds=([bl,x0l,gl,taul],[bu,x0u,gu,tauu]),
                            absolute_sigma=True, full_output=True,
                            sigma=data[str(k)].TFY_on_std[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]/np.sqrt(data[str(k)].N_values_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<fit_range_u)]) )
    # popt, pcov = curve_fit(errorfunction, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]))  
    # popt, pcov = curve_fit(expgauss, 
    #                         data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<10000)] , 
    #                         bounds=([x0l,y0l,al,gl,bl,taul],[x0u,y0u,au,gu,bu,tauu]))
    # popt, pcov = curve_fit(errorfunction, 
    #                        data[str(k)].Delays_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<500)] , 
    #                        data[str(k)].TFY_on[(~np.isnan(data[str(k)]).any(axis=1))&(data[str(k)].Delays_on<500)])
    fit_param[str(k)] = popt
    fit_param2[str(k)] = pcov
    fit_param3[str(k)] = np.sqrt(np.diag(pcov))
    chisq[str(k)] = sum(( (data[str(k)].TFY_on - custom_conv(data[str(k)].Delays_on, *fit_param[str(k)])) / data[str(k)].TFY_on_std )**2) / np.size(data[str(k)].Delays_on)
perr = np.sqrt(np.diag(pcov))
for k in Runs:
    plt.figure(k)
    # plt.plot(data[str(k)].Delays_on, data[str(k)].TFY_on - data[str(k)].TFY_off)
    plt.errorbar(data[str(k)].Delays_on, data[str(k)].TFY_on - data[str(k)].TFY_off, yerr=data[str(k)].TFY_on_std/np.sqrt(data[str(k)].N_values_on))
    plt.plot(data[str(k)].Delays_on, custom_conv(data[str(k)].Delays_on, *fit_param[str(k)]))
    plt.xlim([-600,10000])
    
New_Delays = {}
plt.figure(2)
for k in Runs:
    New_Delays[str(k)] = data[str(k)].Delays_on - fit_param[str(k)][1]
    plt.plot(New_Delays[str(k)] , (data[str(k)].TFY_on-data[str(k)].TFY_off)/fit_param[str(k)][0])
    plt.xlim([-600,10000])
'''